{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug print flag \n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(state_or_action):\n",
    "    return ('-'.join(str(e) for e in state_or_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_tracking_states(state_space, action_space):\n",
    "    for state in state_space:\n",
    "        for action in action_space:\n",
    "            state_str = to_string(state)\n",
    "            action_str = to_string(action)\n",
    "            States_track[state_str][action_str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracking_states(curr_state, curr_action, q_value):\n",
    "    for state in States_track.keys():\n",
    "        if state == curr_state:\n",
    "            for action in States_track[state].keys():\n",
    "                if action == curr_action:\n",
    "                    States_track[state][action].append(q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defining a function to save the Q-dictionary as a pickle file\n",
    "# def save_obj(obj, name ):\n",
    "#     with open(name + '.pkl', 'wb') as f:\n",
    "#         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, action_space):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.action_space = action_space\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001       \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = 0.00065 #0.999\n",
    "        self.epsilon_min = 0\n",
    "        \n",
    "        self.batch_size = 32    \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        # model.summary() \n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "    def get_epsilon(self, time):\n",
    "        return self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-self.epsilon_decay*time)\n",
    "\n",
    "    def get_action(self, state, time):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in ε after we generate each sample from the environment       \n",
    "\n",
    "        epsilon = self.get_epsilon(time)\n",
    "\n",
    "        possible_actions_index, all_possible_actions = env.requests(state)\n",
    "\n",
    "        if len(possible_actions_index) == 0:\n",
    "            return all_possible_actions[0]\n",
    "\n",
    "        if (np.random.rand() <= epsilon):\n",
    "            return random.choice(all_possible_actions)\n",
    "        # if generated random number is greater than ε, choose the action which has max Q-value\n",
    "        else:\n",
    "            state = env.state_encod_arch1(state)\n",
    "            state = state.reshape(1, self.state_size)\n",
    "            q_values = self.model.predict(state)[0]\n",
    "            \n",
    "            argmax = np.argmax(q_values[possible_actions_index])\n",
    "#             DEBUG and print(f'q_values: {q_values}, available_q_vals: {q_values[possible_actions_index]}, argmax: {argmax}, all_possible_actions: {all_possible_actions}')\n",
    "            return all_possible_actions[argmax]\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, isTerminal):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state, isTerminal))\n",
    "    \n",
    "    def get_q_values(self, state):\n",
    "        return self.model.predict(state)[0]\n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards, terminal_states  = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, isTerminal = mini_batch[i]\n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                update_input[i] = env.state_encod_arch1(state).reshape(1, self.state_size)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch1(next_state).reshape(1, self.state_size)   \n",
    "                terminal_states.append(isTerminal)\n",
    "                \n",
    "            # 2. Get the target for the Q-network\n",
    "            target = self.model.predict(update_input)\n",
    "            target_qval = self.model.predict(update_output)\n",
    "            \n",
    "            #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                action_idx = action_space.index(actions[i])\n",
    "                if terminal_states[i]:                    \n",
    "                    target[i][action_idx] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][action_idx] = rewards[i] + self.discount_factor * np.max(target_qval[i])                    \n",
    "                    \n",
    "            # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 1000\n",
    "\n",
    "env = CabDriver()\n",
    "action_space, state_space, state = env.reset()\n",
    "action_size = len(action_space)\n",
    "state_size = len(env.state_encod_arch1(state_space[0]))\n",
    "\n",
    "agent = DQNAgent(state_size, action_size, action_space)\n",
    "\n",
    "States_track = collections.defaultdict(dict)\n",
    "initialise_tracking_states(state_space, action_space)\n",
    "\n",
    "# create folder with current time stamp\n",
    "DIR_NAME = os.path.join(\n",
    "        os.getcwd(), \n",
    "        'model-' + datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "os.makedirs(DIR_NAME)\n",
    "\n",
    "agent.epsilon_decay = 80.0/(Episodes * 10)\n",
    "\n",
    "scores = {}\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015E9D690A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000015E9D690A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015E9FEEB048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015E9FEEB048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Score 0: -12.0\n",
      "Score 1: 73.0\n",
      "Score 2: 44.0\n",
      "Score 3: 294.0\n",
      "Score 4: 196.0\n",
      "Score 5: 293.0\n",
      "Score 6: 33.0\n",
      "Score 7: 298.0\n",
      "Score 8: 456.0\n",
      "Score 9: 268.0\n",
      "Score 10: 407.0\n",
      "Score 11: 342.0\n",
      "Score 12: 659.0\n",
      "Score 13: 843.0\n",
      "Score 14: 497.0\n",
      "Score 15: 550.0\n",
      "Score 16: 507.0\n",
      "Score 17: 284.0\n",
      "Score 18: 396.0\n",
      "Score 19: 666.0\n",
      "Score 20: 358.0\n",
      "Score 21: 576.0\n",
      "Score 22: 497.0\n",
      "Score 23: 669.0\n",
      "Score 24: 617.0\n",
      "Score 25: 570.0\n",
      "Score 26: 930.0\n",
      "Score 27: 779.0\n",
      "Score 28: 398.0\n",
      "Score 29: 561.0\n",
      "Score 30: 754.0\n",
      "Score 31: 969.0\n",
      "Score 32: 710.0\n",
      "Score 33: 650.0\n",
      "Score 34: 790.0\n",
      "Score 35: 458.0\n",
      "Score 36: 479.0\n",
      "Score 37: 701.0\n",
      "Score 38: 897.0\n",
      "Score 39: 760.0\n",
      "Score 40: 743.0\n",
      "Score 41: 768.0\n",
      "Score 42: 882.0\n",
      "Score 43: 749.0\n",
      "Score 44: 881.0\n",
      "Score 45: 849.0\n",
      "Score 46: 768.0\n",
      "Score 47: 1164.0\n",
      "Score 48: 1033.0\n",
      "Score 49: 984.0\n",
      "Entire Operation took 1788.6133193969727 seconds\n"
     ]
    }
   ],
   "source": [
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    \n",
    "\n",
    "    #Call the DQN agent\n",
    "\n",
    "    day = 0\n",
    "    score = 0\n",
    "    terminal_state = False\n",
    "\n",
    "    # reset the state before new episode\n",
    "    _, _, state = env.reset()\n",
    "    initial_state = state\n",
    "        \n",
    "    while not terminal_state:        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        \n",
    "        action = agent.get_action(state, episode)\n",
    "\n",
    "        # 2. Evaluate your reward and next state\n",
    "        next_state, reward = env.step(state, action, Time_matrix)\n",
    "        \n",
    "        # 3. Append the experience to the memory\n",
    "        agent.append_sample(state, action, reward, next_state, terminal_state)\n",
    "        \n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model()\n",
    "        \n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        score += reward\n",
    "        \n",
    "        # increase the date if the day is changed\n",
    "        if next_state[2] != state[2]:\n",
    "            day = day + 1\n",
    "        \n",
    "        DEBUG and print(f'state: {state}, action: {action}, next_state: {next_state}, reward: {reward}, day: {day}')\n",
    "\n",
    "        # for tracking\n",
    "        state_enc = env.state_encod_arch1(state)\n",
    "        state_enc = np.reshape(state_enc, [1, 36])\n",
    "        q_values = agent.get_q_values(state_enc)\n",
    "        \n",
    "        state_string = to_string(state)\n",
    "        \n",
    "        for index in range(len(env.action_space)):\n",
    "            action_string = to_string(env.action_space[index])\n",
    "            save_tracking_states(state_string, action_string, q_values[index])\n",
    "            \n",
    "        if day > 30:\n",
    "            terminal_state = True\n",
    "            \n",
    "        state = next_state\n",
    "\n",
    "    print(f'Score {episode}: {score}')\n",
    "    scores[episode] = score\n",
    "    \n",
    "    if ((episode + 1) % 10 == 0):\n",
    "        agent.save(DIR_NAME + '\\\\' + str(episode) + '.h5')\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Entire Operation took {elapsed_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot score values\n",
    "\n",
    "plt.bar(*zip(*scores.items()))\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final model\n",
    "\n",
    "agent.save(DIR_NAME + '\\\\final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "States_track[1-2-0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time_arr = np.arange(0,1000)\n",
    "epsilon = []\n",
    "for i in range(0,Episodes):\n",
    "    # epsilon.append(0 + (1 - 0) * np.exp(-0.0008*i))\n",
    "    epsilon.append(agent.get_epsilon(i))\n",
    "\n",
    "plt.plot(np.arange(0,Episodes), epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
